name: MLOps Training Pipeline

on:
  push:
    branches: [ main ]
    paths:
      - 'marketing-ml-mvp/**'
      - 'data/**'
  workflow_dispatch:
    inputs:
      force_retrain:
        description: 'Force model retraining'
        required: false
        default: 'false'

env:
  GCP_PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
  GCP_REGION: us-central1
  TRAINING_FUNCTION_URL: ${{ secrets.TRAINING_FUNCTION_URL }}

jobs:
  trigger-training:
    runs-on: ubuntu-latest
    name: Trigger Model Training in GCP
    
    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 2

    - name: Detect Changes
      id: changes
      run: |
        if git diff --name-only HEAD~1 HEAD | grep -E "(marketing-ml-mvp|data)" > /dev/null || [ "${{ github.event.inputs.force_retrain }}" == "true" ]; then
          echo "training_needed=true" >> $GITHUB_OUTPUT
          echo "[DEPLOY] Changes detected in ML pipeline or data - Training needed"
        else
          echo "training_needed=false" >> $GITHUB_OUTPUT
          echo "[INFO] No relevant changes detected - Skipping training"
        fi

    - name: Validate GCP Secrets
      if: steps.changes.outputs.training_needed == 'true'
      run: |
        if [ -z "${{ secrets.GCP_SA_KEY }}" ]; then
          echo "[ERROR] GCP_SA_KEY secret is not set or is empty"
          echo "[INFO] Please check your GitHub repository secrets"
          exit 1
        fi
        echo "[SUCCESS] GCP_SA_KEY secret is configured"

    - name: Setup GCP Authentication
      if: steps.changes.outputs.training_needed == 'true'
      uses: google-github-actions/auth@v2
      with:
        credentials_json: ${{ secrets.GCP_SA_KEY }}
        project_id: ${{ secrets.GCP_PROJECT_ID }}

    - name: Setup Google Cloud SDK
      if: steps.changes.outputs.training_needed == 'true'
      uses: google-github-actions/setup-gcloud@v2

    - name: Verify GCP Authentication
      if: steps.changes.outputs.training_needed == 'true'
      run: |
        echo "[INFO] Testing GCP authentication..."
        gcloud auth list
        gcloud config list project
        
        # Test access token generation
        TOKEN=$(gcloud auth print-access-token 2>/dev/null)
        if [ -z "$TOKEN" ]; then
          echo "[ERROR] Failed to generate access token"
          exit 1
        fi
        echo "[SUCCESS] GCP authentication verified"

    - name: Trigger Training in GCP
      if: steps.changes.outputs.training_needed == 'true'
      run: |
        echo "[DEPLOY] Triggering model training in GCP..."
        
        # Debug: Show environment variables
        echo "[DEBUG] TRAINING_FUNCTION_URL: ${{ env.TRAINING_FUNCTION_URL }}"
        echo "[DEBUG] GCP_PROJECT_ID: ${{ env.GCP_PROJECT_ID }}"
        
        # Get commit info for metadata
        COMMIT_SHA="${{ github.sha }}"
        COMMIT_MSG="${{ github.event.head_commit.message }}"
        AUTHOR="${{ github.event.head_commit.author.name }}"
        
        echo "[DEBUG] Commit SHA: $COMMIT_SHA"
        echo "[DEBUG] Testing access token..."
        gcloud auth print-access-token > /dev/null
        echo "[DEBUG] Access token OK"
        
        # Create JSON payload separately to avoid escaping issues
        cat > payload.json << EOF
        {
          "trigger_source": "github_actions",
          "commit_sha": "$COMMIT_SHA",
          "commit_message": "$COMMIT_MSG",
          "author": "$AUTHOR",
          "branch": "${{ github.ref_name }}",
          "repository": "${{ github.repository }}"
        }
        EOF
        
        echo "[DEBUG] JSON Payload:"
        cat payload.json
        
        # Call Cloud Function to trigger training
        echo "[DEBUG] Calling Cloud Function..."
        HTTP_CODE=$(curl -s -w "%{http_code}" -o response.json \
          -X POST "${{ env.TRAINING_FUNCTION_URL }}" \
          -H "Content-Type: application/json" \
          -H "Authorization: Bearer $(gcloud auth print-access-token)" \
          -d @payload.json)
        
        echo "[DEBUG] HTTP Response Code: $HTTP_CODE"
        echo "[DEBUG] Response content:"
        cat response.json
        
        if [ "$HTTP_CODE" -eq 200 ]; then
          echo "[SUCCESS] Training triggered successfully"
          
          # Extract job_id for monitoring
          JOB_ID=$(cat response.json | jq -r '.job_id // empty')
          if [ ! -z "$JOB_ID" ]; then
            echo "[METRICS] Training Job ID: $JOB_ID"
            echo "job_id=$JOB_ID" >> $GITHUB_OUTPUT
          fi
        else
          echo "[ERROR] Failed to trigger training. HTTP Code: $HTTP_CODE"
          echo "[ERROR] Response:"
          cat response.json
          exit 1
        fi
      id: trigger

    - name: Monitor Training Progress
      if: steps.changes.outputs.training_needed == 'true' && steps.trigger.outputs.job_id
      run: |
        JOB_ID="${{ steps.trigger.outputs.job_id }}"
        echo "[METRICS] Monitoring training job: $JOB_ID"
        
        # Monitor for up to 30 minutes
        for i in {1..60}; do
          echo "[WAIT] Check #$i - Monitoring training progress..."
          
          STATUS_RESPONSE=$(curl -s \
            "${{ env.TRAINING_FUNCTION_URL }}/status?job_id=$JOB_ID" \
            -H "Authorization: Bearer $(gcloud auth print-access-token)")
          
          echo "$STATUS_RESPONSE" | jq .
          
          TRAINING_COMPLETED=$(echo "$STATUS_RESPONSE" | jq -r '.training_completed // false')
          INSTANCE_STATUS=$(echo "$STATUS_RESPONSE" | jq -r '.instance_status // "UNKNOWN"')
          
          if [ "$TRAINING_COMPLETED" == "true" ]; then
            echo "[SUCCESS] Training completed successfully!"
            echo "[DONE] Model is now available in Cloud Storage"
            break
          elif [ "$INSTANCE_STATUS" == "TERMINATED" ] && [ "$TRAINING_COMPLETED" != "true" ]; then
            echo "[ERROR] Training instance terminated but training not completed"
            exit 1
          fi
          
          echo "[SYNC] Training in progress... (Status: $INSTANCE_STATUS)"
          sleep 30
        done

    - name: Create Training Summary
      if: steps.changes.outputs.training_needed == 'true'
      run: |
        cat > training_summary.md << EOF
        # MLOps Training Summary
        
        **Commit:** \`${{ github.sha }}\`  
        **Branch:** \`${{ github.ref_name }}\`  
        **Author:** ${{ github.event.head_commit.author.name }}  
        **Trigger:** GitHub Actions  
        **Timestamp:** $(date -u)
        
        ## Training Details
        - **Job ID:** ${{ steps.trigger.outputs.job_id || 'N/A' }}
        - **GCP Project:** ${{ env.GCP_PROJECT_ID }}
        - **Region:** ${{ env.GCP_REGION }}
        
        ## Changes Detected
        $(git diff --name-only HEAD~1 HEAD | grep -E "(marketing-ml-mvp|data)" || echo "Force retrain requested")
        
        ## Next Steps
        1. [SUCCESS] Model trained and uploaded to Cloud Storage
        2. [SYNC] Local Streamlit app can now sync the updated model
        3. [METRICS] Check \`gs://blend-mlops-models-${{ env.GCP_PROJECT_ID }}/models/latest/\`
        
        ---
        *Generated by GitHub Actions MLOps Pipeline*
        EOF
        
        echo "[DOCS] Training Summary Created:"
        cat training_summary.md

    - name: Comment on PR (if applicable)
      if: steps.changes.outputs.training_needed == 'true' && github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        script: |
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: `[DEPLOY] **MLOps Training Triggered**
            
            A new model training has been initiated in GCP due to changes in this PR.
            
            **Training Job ID:** \`${{ steps.trigger.outputs.job_id || 'N/A' }}\`
            **GCP Project:** \`${{ env.GCP_PROJECT_ID }}\`
            
            The model will be available shortly at:
            \`gs://blend-mlops-models-${{ env.GCP_PROJECT_ID }}/models/latest/\`
            
            You can sync the updated model in your local Streamlit app! [TARGET]`
          })

  notify-completion:
    runs-on: ubuntu-latest
    needs: trigger-training
    if: always()
    name: Notify Results
    
    steps:
    - name: Training Results
      run: |
        if [ "${{ needs.trigger-training.result }}" == "success" ]; then
          echo "[DONE] MLOps Training Pipeline completed successfully!"
          echo "[PACKAGE] Updated model is now available in Cloud Storage"
          echo "[SYNC] Local applications can sync the new model"
        else
          echo "[ERROR] MLOps Training Pipeline failed or was skipped"
          echo "[DOCS] Check the logs for more details"
        fi