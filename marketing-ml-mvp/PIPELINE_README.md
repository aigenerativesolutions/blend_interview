# ü§ñ MLOps Pipeline Completo - Marketing Campaign Prediction

## üéØ Overview

Este es un pipeline MLOps completo que implementa **exactamente tu metodolog√≠a ganadora del notebook**, automatizado con **GitHub Actions** para CI/CD. Reproduce el flujo completo: Features ‚Üí 3er Tuning ‚Üí Training ‚Üí Calibration ‚Üí SHAP, todo serializado y versionado.

## üìä ¬øQu√© es MLOps?

**MLOps = DevOps para Machine Learning**

- **Automatiza** el entrenamiento cuando cambias datos o c√≥digo
- **Versiona** modelos, datos y c√≥digo
- **Despliega** autom√°ticamente si las m√©tricas mejoran
- **Monitorea** el rendimiento en producci√≥n
- **Reproduce** experimentos exactamente

## üèóÔ∏è Arquitectura del Pipeline

```
üìÅ marketing-ml-mvp/
‚îú‚îÄ‚îÄ ü§ñ pipeline/
‚îÇ   ‚îú‚îÄ‚îÄ feature_engineering.py      # Features serializables (Age, Total_Spent, etc.)
‚îÇ   ‚îú‚îÄ‚îÄ third_tuning.py            # SOLO 3er tuning (metodolog√≠a ganadora)
‚îÇ   ‚îú‚îÄ‚îÄ train_final.py             # Modelo final con mejores params
‚îÇ   ‚îú‚îÄ‚îÄ temperature_calibration.py # Temperature Scaling
‚îÇ   ‚îú‚îÄ‚îÄ shap_analysis_pipeline.py  # SHAP completo + plots
‚îÇ   ‚îî‚îÄ‚îÄ run_pipeline.py            # Orquestador principal
‚îú‚îÄ‚îÄ üîÑ .github/workflows/
‚îÇ   ‚îú‚îÄ‚îÄ ml-pipeline.yml           # CI/CD para entrenamiento
‚îÇ   ‚îî‚îÄ‚îÄ deploy-api.yml            # Despliegue autom√°tico
‚îú‚îÄ‚îÄ üì¶ artifacts/                  # Modelos y resultados serializados
‚îú‚îÄ‚îÄ üåê src/api/                   # API con pipeline integrado
‚îî‚îÄ‚îÄ üìö docs/                      # Documentaci√≥n
```

## üöÄ Flujo de Trabajo Autom√°tico

### 1. **Haces Push a GitHub**
```bash
git add .
git commit -m "Update data or code"
git push origin main
```

### 2. **GitHub Actions se activa autom√°ticamente**
- Detecta cambios en `data/` o `pipeline/`
- Ejecuta el pipeline completo
- Valida calidad del modelo
- Despliega si mejoran las m√©tricas

### 3. **Pipeline MLOps ejecuta:**

#### Step 1: **Feature Engineering** üîß
```python
# Reproduce EXACTAMENTE tu notebook:
- Age = current_year - Year_Birth
- Total_Spent = suma de Mnt*
- Customer_Days desde Dt_Customer
- Codificaci√≥n de Education/Marital_Status
- Scaling de features num√©ricas

# ‚úÖ Serializa: feature_pipeline.pkl
```

#### Step 2: **3er Tuning (Metodolog√≠a Ganadora)** üéØ
```python
# TU configuraci√≥n exacta que gan√≥:
third_param_grid = {
    'n_estimators': [290, 300, 310],
    'max_depth': [5],
    'learning_rate': [0.01],
    'subsample': [0.9],
    'colsample_bytree': [0.8],
    'gamma': [0.05, 0.1],
    'reg_alpha': [0.5],
    'reg_lambda': [2.5, 3.0]
}

# ‚úÖ Serializa: best_params_tuning3.json, optimal_threshold.json
```

#### Step 3: **Entrenamiento Final** üèãÔ∏è
```python
# Entrena con los mejores par√°metros del 3er tuning
# Calcula threshold √≥ptimo con PR curve
# Genera plots de evaluaci√≥n

# ‚úÖ Serializa: final_model.pkl, final_model_metadata.json
```

#### Step 4: **Temperature Calibration** üå°Ô∏è
```python
# Tu implementaci√≥n exacta de Temperature Scaling
# Reliability diagrams antes/despu√©s
# Mejora del Brier Score

# ‚úÖ Serializa: temperature_calibrator.pkl
```

#### Step 5: **SHAP Analysis** üîç
```python
# An√°lisis completo como en tu notebook:
- SHAP values globales
- Feature importance
- Dependence plots (top 10 features)
- Waterfall plots (samples representativos)

# ‚úÖ Serializa: shap_explainer.pkl, shap_values.npz
```

### 4. **API Actualizada Autom√°ticamente** üåê
- Carga todos los artifacts del pipeline
- Endpoints con SHAP integrado
- Predicciones con calibraci√≥n
- Feature engineering autom√°tico

## üìÅ Artifacts Serializados

Todos los componentes se guardan autom√°ticamente:

```
artifacts/
‚îú‚îÄ‚îÄ feature_pipeline.pkl           # Transformador de features fitted
‚îú‚îÄ‚îÄ best_params_tuning3.json      # Mejores par√°metros del 3er tuning
‚îú‚îÄ‚îÄ final_model.pkl               # Modelo XGBoost entrenado
‚îú‚îÄ‚îÄ temperature_calibrator.pkl    # Calibrador de temperatura
‚îú‚îÄ‚îÄ optimal_threshold.json        # Threshold √≥ptimo encontrado
‚îú‚îÄ‚îÄ shap_values/
‚îÇ   ‚îú‚îÄ‚îÄ shap_explainer.pkl        # SHAP explainer
‚îÇ   ‚îú‚îÄ‚îÄ shap_values.npz          # Valores SHAP
‚îÇ   ‚îî‚îÄ‚îÄ global_feature_importance.json
‚îú‚îÄ‚îÄ plots/                        # Todos los plots generados
‚îî‚îÄ‚îÄ pipeline_summary.json        # Resumen completo
```

## üéÆ C√≥mo Usar

### Opci√≥n 1: Ejecutar Pipeline Localmente

```bash
# 1. Instalar dependencias
pip install -r requirements.txt

# 2. Colocar tus datos
cp tu_archivo.csv data/marketing_campaign_data.csv

# 3. Ejecutar pipeline completo
python pipeline/run_pipeline.py \
  --data-path data/marketing_campaign_data.csv \
  --artifacts-dir artifacts

# 4. Ver resultados
cat artifacts/pipeline_summary.json
```

### Opci√≥n 2: GitHub Actions Autom√°tico

```bash
# 1. Subir datos al repo
git add data/marketing_campaign_data.csv
git commit -m "Add training data"
git push origin main

# 2. Ver workflow en GitHub Actions
# - Va a https://github.com/tu-repo/actions
# - El workflow se ejecuta autom√°ticamente
# - Descarga artifacts cuando termine
```

### Opci√≥n 3: API en Producci√≥n

```bash
# Despu√©s del pipeline, la API ya tiene todo:
curl -X POST "https://your-api-url/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "customer": {
      "Education": "Graduation",
      "Marital_Status": "Married", 
      "Income": 58138.0,
      "Year_Birth": 1985,
      "Dt_Customer": "2015-01-01",
      ...
    },
    "use_calibration": true
  }'
```

## üîÑ GitHub Actions Workflow

### `ml-pipeline.yml` - Entrenamiento Autom√°tico

```yaml
# Se activa cuando:
- Push a main/develop
- Cambios en pipeline/ o data/
- Cada domingo (reentrenamiento programado)
- Manualmente con workflow_dispatch

# Ejecuta:
1. Valida datos
2. Ejecuta pipeline completo  
3. Valida m√©tricas (ROC-AUC > 0.75, F1 > 0.60)
4. Sube artifacts
5. Triggea despliegue si pasa calidad
```

### `deploy-api.yml` - Despliegue Autom√°tico

```yaml
# Se activa cuando:
- El pipeline de entrenamiento termina exitoso
- Manualmente para staging/production

# Ejecuta:
1. Build Docker con artifacts
2. Deploy a Cloud Run staging
3. Health checks y API tests
4. Deploy a production con traffic split gradual
```

## üìä Monitoreo y M√©tricas

### M√©tricas de Calidad
- **ROC-AUC**: Debe ser ‚â• 0.75
- **F1-Score**: Debe ser ‚â• 0.60
- **Brier Improvement**: Mejora con calibraci√≥n
- **Temperature**: Par√°metro de calibraci√≥n

### Artifacts Versionados
- Cada run genera artifacts con timestamp
- Modelos se guardan en GCS con versi√≥n
- Registry de modelos autom√°tico
- Rollback f√°cil a versiones anteriores

## üö® Qu√© Pasa si Falla

### Fallos Comunes y Soluciones

1. **"Data file not found"**
   ```bash
   # Soluci√≥n: Subir archivo de datos
   cp tu_archivo.csv data/marketing_campaign_data.csv
   git add data/marketing_campaign_data.csv
   git commit -m "Add data"
   git push
   ```

2. **"Model quality below thresholds"**
   ```bash
   # El modelo no pasa calidad (ROC-AUC < 0.75)
   # Revisa los datos o ajusta thresholds en .github/workflows/ml-pipeline.yml
   ```

3. **"Pipeline artifacts not found"**
   ```bash
   # API no encuentra artifacts
   # Ejecuta pipeline localmente o revisa GitHub Actions
   python pipeline/run_pipeline.py --data-path data/marketing_campaign_data.csv
   ```

## üéØ Para tu Entrevista

### Lo que puedes mostrar:

1. **Pipeline Completo**: "Implement√© MLOps end-to-end"
2. **Metodolog√≠a Ganadora**: "Us√© mi 3er tuning que dio mejores resultados"
3. **CI/CD Autom√°tico**: "Push = entrenamiento + despliegue autom√°tico"
4. **Serializaci√≥n**: "Todo versionado y reproducible"
5. **Monitoreo**: "Validaci√≥n autom√°tica de calidad"
6. **SHAP Integrado**: "Explicabilidad en la API"

### Preguntas que puedes responder:

- **"¬øC√≥mo garantizas reproducibilidad?"** ‚Üí "Versionado de c√≥digo, datos y modelos"
- **"¬øC√≥mo manejas el modelo drift?"** ‚Üí "Reentrenamiento autom√°tico programado"
- **"¬øC√≥mo despliegas modelos?"** ‚Üí "CI/CD con validaci√≥n autom√°tica"
- **"¬øC√≥mo explicas predicciones?"** ‚Üí "SHAP integrado en la API"

## üîß Configuraci√≥n Avanzada

### Secrets de GitHub (Requeridos para GCP)

```bash
# En GitHub repo ‚Üí Settings ‚Üí Secrets:
GCP_SA_KEY: [Service Account Key JSON]
GCP_PROJECT_ID: tu-proyecto-gcp  
GCS_BUCKET: tu-bucket-models
```

### Configuraci√≥n del Pipeline

```python
# En pipeline/run_pipeline.py puedes ajustar:
- test_size: Proporci√≥n test set
- val_split: Proporci√≥n validation
- Thresholds de calidad
- Par√°metros del tuning
```

### Triggers Personalizados

```yaml
# En .github/workflows/ml-pipeline.yml:
schedule:
  - cron: '0 2 * * 0'  # Cada domingo 2:00 AM
  
# Cambiar por tu horario preferido
```

## üèÜ Ventajas de este Approach

1. **‚úÖ Reproduce tu metodolog√≠a exacta**
2. **üöÄ Automatizaci√≥n completa**
3. **üì¶ Versionado de todo**
4. **üîç Trazabilidad total**
5. **‚ö° Despliegue sin downtime**
6. **üìä Monitoreo continuo**
7. **üîÑ Rollback f√°cil**
8. **üéØ Production-ready**

## üìû Troubleshooting

### Ver logs del pipeline:
```bash
# Localmente:
tail -f pipeline.log

# En GitHub Actions:
# Ve a Actions tab ‚Üí Select workflow run ‚Üí Expand steps
```

### Test manual de la API:
```bash
# Health check
curl https://your-api-url/health

# Predict con datos sample
curl https://your-api-url/model/sample-input
curl -X POST https://your-api-url/predict -d @sample.json
```

### Debug artifacts:
```bash
# Ver qu√© se gener√≥
ls -la artifacts/
python -c "import json; print(json.load(open('artifacts/pipeline_summary.json')))"
```

---

## üéâ ¬°Tu pipeline MLOps est√° listo!

Este setup te da **credibilidad t√©cnica m√°xima** para tu entrevista. Muestra conocimiento de:

- **ML Engineering** (tu metodolog√≠a optimizada)
- **MLOps** (CI/CD, versionado, monitoreo)  
- **Cloud Native** (Docker, GCP, APIs)
- **Best Practices** (testing, serializaci√≥n, documentaci√≥n)

**¬°Buena suerte en tu entrevista! üöÄ**