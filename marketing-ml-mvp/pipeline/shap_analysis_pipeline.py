"""
SHAP Analysis Pipeline - Serializable
Análisis completo de SHAP con dependence plots y serialización
"""
import numpy as np
import pandas as pd
import shap
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
import json
from pathlib import Path
import logging
from typing import Dict, Any, List, Tuple, Optional
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

logger = logging.getLogger(__name__)

class SHAPAnalysisPipeline:
    \"\"\"\n    Pipeline completo de análisis SHAP serializable\n    Reproduce exactamente el análisis del notebook\n    \"\"\"\n    \n    def __init__(self):\n        self.explainer = None\n        self.shap_values = None\n        self.expected_value = None\n        self.feature_names = []\n        self.is_fitted = False\n        self.background_data = None\n    \n    def create_explainer(self, model, background_data: np.ndarray, \n                        feature_names: List[str]) -> None:\n        \"\"\"\n        Crear explainer SHAP para el modelo\n        \"\"\"\n        logger.info(\"🔍 Creando SHAP explainer...\")\n        \n        self.feature_names = feature_names\n        self.background_data = background_data\n        \n        # Usar TreeExplainer para XGBoost (más rápido y preciso)\n        self.explainer = shap.TreeExplainer(model)\n        self.expected_value = self.explainer.expected_value\n        \n        # Si expected_value es array, tomar el valor para clase positiva\n        if isinstance(self.expected_value, (list, np.ndarray)):\n            self.expected_value = self.expected_value[1] if len(self.expected_value) > 1 else self.expected_value[0]\n        \n        self.is_fitted = True\n        logger.info(f\" SHAP explainer creado. Expected value: {self.expected_value:.4f}\")\n    \n    def calculate_shap_values(self, X: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Calcular SHAP values para el dataset\n        \"\"\"\n        if not self.is_fitted:\n            raise ValueError(\"Debe crear el explainer primero\")\n        \n        logger.info(f\"🔄 Calculando SHAP values para {X.shape[0]} samples...\")\n        \n        # Calcular SHAP values\n        shap_values = self.explainer.shap_values(X)\n        \n        # TreeExplainer puede retornar lista o array\n        if isinstance(shap_values, list):\n            # Para clasificación binaria, tomar clase positiva (índice 1)\n            shap_values = shap_values[1] if len(shap_values) > 1 else shap_values[0]\n        \n        self.shap_values = shap_values\n        logger.info(f\" SHAP values calculados. Shape: {shap_values.shape}\")\n        \n        return shap_values\n    \n    def get_global_feature_importance(self) -> Dict[str, float]:\n        \"\"\"\n        Obtener importancia global de features usando SHAP\n        \"\"\"\n        if self.shap_values is None:\n            raise ValueError(\"Debe calcular SHAP values primero\")\n        \n        # Importancia basada en valor absoluto medio\n        importance = np.abs(self.shap_values).mean(axis=0)\n        \n        # Crear diccionario con nombres de features\n        feature_importance = dict(zip(self.feature_names, importance))\n        \n        # Ordenar por importancia\n        sorted_importance = dict(\n            sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)\n        )\n        \n        logger.info(f\"📊 Top 5 features: {list(sorted_importance.keys())[:5]}\")\n        \n        return sorted_importance\n    \n    def create_summary_plot(self, X: np.ndarray, artifacts_dir: Path, \n                           plot_type: str = 'dot', max_display: int = 20) -> None:\n        \"\"\"\n        Crear summary plot de SHAP\n        \"\"\"\n        logger.info(f\"📈 Generando SHAP summary plot ({plot_type})...\")\n        \n        plots_dir = artifacts_dir / \"plots\" / \"shap\"\n        plots_dir.mkdir(parents=True, exist_ok=True)\n        \n        # Crear DataFrame para mejor visualización\n        X_df = pd.DataFrame(X, columns=self.feature_names)\n        \n        plt.figure(figsize=(12, 8))\n        \n        if plot_type == 'dot':\n            shap.summary_plot(\n                self.shap_values, X_df, \n                max_display=max_display,\n                show=False\n            )\n        elif plot_type == 'bar':\n            shap.summary_plot(\n                self.shap_values, X_df,\n                plot_type='bar',\n                max_display=max_display,\n                show=False\n            )\n        elif plot_type == 'violin':\n            shap.summary_plot(\n                self.shap_values, X_df,\n                plot_type='violin',\n                max_display=max_display,\n                show=False\n            )\n        \n        plt.title(f'SHAP Summary Plot ({plot_type.title()})', fontsize=16, pad=20)\n        plt.tight_layout()\n        plt.savefig(plots_dir / f\"summary_plot_{plot_type}.png\", dpi=300, bbox_inches='tight')\n        plt.close()\n    \n    def create_dependence_plots(self, X: np.ndarray, artifacts_dir: Path,\n                               top_n_features: int = 10) -> Dict[str, str]:\n        \"\"\"\n        Crear dependence plots para las top N features\n        \"\"\"\n        logger.info(f\"📈 Generando SHAP dependence plots para top {top_n_features} features...\")\n        \n        plots_dir = artifacts_dir / \"plots\" / \"shap\" / \"dependence\"\n        plots_dir.mkdir(parents=True, exist_ok=True)\n        \n        # Obtener top features\n        feature_importance = self.get_global_feature_importance()\n        top_features = list(feature_importance.keys())[:top_n_features]\n        \n        # Crear DataFrame\n        X_df = pd.DataFrame(X, columns=self.feature_names)\n        \n        dependence_plots = {}\n        \n        for feature in top_features:\n            try:\n                plt.figure(figsize=(10, 6))\n                \n                # SHAP dependence plot\n                feature_idx = self.feature_names.index(feature)\n                shap.dependence_plot(\n                    feature_idx, self.shap_values, X_df,\n                    show=False\n                )\n                \n                plt.title(f'SHAP Dependence Plot: {feature}', fontsize=14, pad=20)\n                plt.tight_layout()\n                \n                plot_filename = f\"dependence_{feature.lower().replace(' ', '_')}.png\"\n                plot_path = plots_dir / plot_filename\n                plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n                plt.close()\n                \n                dependence_plots[feature] = str(plot_path)\n                \n            except Exception as e:\n                logger.warning(f\" Error creando dependence plot para {feature}: {e}\")\n                continue\n        \n        logger.info(f\"📈 {len(dependence_plots)} dependence plots guardados\")\n        \n        return dependence_plots\n    \n    def create_waterfall_plots(self, X: np.ndarray, artifacts_dir: Path,\n                              sample_indices: Optional[List[int]] = None,\n                              max_samples: int = 5) -> List[str]:\n        \"\"\"\n        Crear waterfall plots para samples específicos\n        \"\"\"\n        logger.info(f\"📈 Generando SHAP waterfall plots...\")\n        \n        plots_dir = artifacts_dir / \"plots\" / \"shap\" / \"waterfall\"\n        plots_dir.mkdir(parents=True, exist_ok=True)\n        \n        # Si no se especifican índices, tomar samples aleatorios\n        if sample_indices is None:\n            np.random.seed(42)\n            sample_indices = np.random.choice(len(X), size=min(max_samples, len(X)), replace=False)\n        \n        X_df = pd.DataFrame(X, columns=self.feature_names)\n        waterfall_plots = []\n        \n        for i, idx in enumerate(sample_indices):\n            try:\n                plt.figure(figsize=(12, 8))\n                \n                # Crear waterfall plot personalizado (compatible con versiones de SHAP)\n                sample_shap_values = self.shap_values[idx]\n                sample_features = X_df.iloc[idx]\n                \n                self._create_custom_waterfall_plot(\n                    sample_shap_values, sample_features, self.expected_value\n                )\n                \n                plt.title(f'SHAP Waterfall Plot - Sample {idx}', fontsize=14, pad=20)\n                plt.tight_layout()\n                \n                plot_filename = f\"waterfall_sample_{idx}.png\"\n                plot_path = plots_dir / plot_filename\n                plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n                plt.close()\n                \n                waterfall_plots.append(str(plot_path))\n                \n            except Exception as e:\n                logger.warning(f\" Error creando waterfall plot para sample {idx}: {e}\")\n                continue\n        \n        logger.info(f\"📈 {len(waterfall_plots)} waterfall plots guardados\")\n        \n        return waterfall_plots\n    \n    def _create_custom_waterfall_plot(self, shap_values: np.ndarray, \n                                     features: pd.Series, expected_value: float,\n                                     max_features: int = 15) -> None:\n        \"\"\"\n        Crear waterfall plot personalizado\n        \"\"\"\n        # Ordenar features por valor absoluto de SHAP\n        feature_importance = np.abs(shap_values)\n        sorted_idx = np.argsort(feature_importance)[::-1][:max_features]\n        \n        sorted_features = [self.feature_names[i] for i in sorted_idx]\n        sorted_shap_values = shap_values[sorted_idx]\n        sorted_feature_values = [features.iloc[i] for i in sorted_idx]\n        \n        # Colores\n        colors = ['red' if val < 0 else 'blue' for val in sorted_shap_values]\n        \n        # Crear plot\n        y_pos = np.arange(len(sorted_features))\n        \n        plt.barh(y_pos, sorted_shap_values, color=colors, alpha=0.7)\n        plt.yticks(y_pos, [f\"{feat} = {val:.3f}\" for feat, val in zip(sorted_features, sorted_feature_values)])\n        plt.xlabel('SHAP Value (Impact on Model Output)')\n        plt.axvline(x=0, color='black', linestyle='-', alpha=0.5)\n        \n        # Añadir expected value\n        plt.axvline(x=expected_value, color='gray', linestyle='--', alpha=0.7, \n                   label=f'Expected Value: {expected_value:.3f}')\n        \n        plt.legend()\n        plt.grid(axis='x', alpha=0.3)\n    \n    def save_analysis_results(self, artifacts_dir: Path, \n                             feature_importance: Dict[str, float]) -> None:\n        \"\"\"\n        Guardar todos los resultados del análisis SHAP\n        \"\"\"\n        logger.info(\"💾 Guardando resultados de análisis SHAP...\")\n        \n        shap_dir = artifacts_dir / \"shap_values\"\n        shap_dir.mkdir(parents=True, exist_ok=True)\n        \n        # Guardar SHAP explainer\n        explainer_path = shap_dir / \"shap_explainer.pkl\"\n        joblib.dump(self.explainer, explainer_path)\n        \n        # Guardar SHAP values\n        values_path = shap_dir / \"shap_values.npz\"\n        np.savez_compressed(values_path, \n                           shap_values=self.shap_values,\n                           expected_value=self.expected_value,\n                           feature_names=self.feature_names)\n        \n        # Guardar feature importance\n        importance_path = shap_dir / \"global_feature_importance.json\"\n        with open(importance_path, 'w') as f:\n            json.dump(feature_importance, f, indent=2)\n        \n        # Guardar metadatos\n        metadata = {\n            'expected_value': float(self.expected_value),\n            'n_samples': int(self.shap_values.shape[0]),\n            'n_features': int(self.shap_values.shape[1]),\n            'feature_names': self.feature_names,\n            'timestamp': datetime.now().isoformat(),\n            'version': '1.0.0'\n        }\n        \n        metadata_path = shap_dir / \"shap_metadata.json\"\n        with open(metadata_path, 'w') as f:\n            json.dump(metadata, f, indent=2)\n        \n        logger.info(f\"💾 SHAP analysis guardado en {shap_dir}\")\n    \n    @classmethod\n    def load_analysis_results(cls, artifacts_dir: Path) -> 'SHAPAnalysisPipeline':\n        \"\"\"\n        Cargar resultados de análisis SHAP previamente guardados\n        \"\"\"\n        shap_dir = artifacts_dir / \"shap_values\"\n        \n        # Cargar explainer\n        explainer_path = shap_dir / \"shap_explainer.pkl\"\n        explainer = joblib.load(explainer_path)\n        \n        # Cargar SHAP values\n        values_path = shap_dir / \"shap_values.npz\"\n        data = np.load(values_path)\n        \n        # Crear instancia\n        pipeline = cls()\n        pipeline.explainer = explainer\n        pipeline.shap_values = data['shap_values']\n        pipeline.expected_value = float(data['expected_value'])\n        pipeline.feature_names = data['feature_names'].tolist()\n        pipeline.is_fitted = True\n        \n        logger.info(f\"📂 SHAP analysis cargado desde {shap_dir}\")\n        \n        return pipeline\n\ndef run_complete_shap_analysis(model, X: np.ndarray, feature_names: List[str],\n                              artifacts_dir: Path, background_data: Optional[np.ndarray] = None) -> Dict[str, Any]:\n    \"\"\"\n    Ejecutar análisis completo de SHAP\n    \"\"\"\n    logger.info(\"🔍 Iniciando análisis completo de SHAP...\")\n    \n    # Usar subset para background si no se proporciona\n    if background_data is None:\n        background_data = X[:100] if len(X) > 100 else X\n    \n    # Crear pipeline\n    shap_pipeline = SHAPAnalysisPipeline()\n    \n    # 1. Crear explainer\n    shap_pipeline.create_explainer(model, background_data, feature_names)\n    \n    # 2. Calcular SHAP values\n    shap_values = shap_pipeline.calculate_shap_values(X)\n    \n    # 3. Obtener feature importance\n    feature_importance = shap_pipeline.get_global_feature_importance()\n    \n    # 4. Generar plots\n    # Summary plots\n    shap_pipeline.create_summary_plot(X, artifacts_dir, 'dot')\n    shap_pipeline.create_summary_plot(X, artifacts_dir, 'bar')\n    \n    # Dependence plots\n    dependence_plots = shap_pipeline.create_dependence_plots(X, artifacts_dir)\n    \n    # Waterfall plots para samples representativos\n    waterfall_plots = shap_pipeline.create_waterfall_plots(X, artifacts_dir)\n    \n    # 5. Guardar resultados\n    shap_pipeline.save_analysis_results(artifacts_dir, feature_importance)\n    \n    logger.info(\" Análisis completo de SHAP finalizado\")\n    \n    return {\n        'shap_pipeline': shap_pipeline,\n        'feature_importance': feature_importance,\n        'dependence_plots': dependence_plots,\n        'waterfall_plots': waterfall_plots,\n        'expected_value': shap_pipeline.expected_value\n    }\n\nif __name__ == \"__main__\":\n    logging.basicConfig(level=logging.INFO)\n    \n    print(\"🔍 Script de SHAP Analysis Pipeline\")\n    print(\"Usar run_pipeline.py para ejecutar el pipeline completo\")