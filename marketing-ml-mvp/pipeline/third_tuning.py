"""
3er Hyperparameter Tuning - MetodologÃ­a Ganadora con Optuna
ImplementaciÃ³n exacta del tercer tuning que dio mejores resultados usando optimizaciÃ³n bayesiana
"""
import numpy as np
import pandas as pd
import optuna
from optuna.samplers import TPESampler
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import f1_score, roc_auc_score, precision_recall_curve
from xgboost import XGBClassifier
import json
import joblib
from pathlib import Path
import logging
from typing import Dict, Any, Tuple
from datetime import datetime

logger = logging.getLogger(__name__)

class OptunaXGBoostOptimizer:
    """
    ImplementaciÃ³n del 3er tuning usando Optuna - metodologÃ­a ganadora del notebook
    """
    
    def __init__(self):
        self.best_params = None
        self.best_score = None
        self.study = None
        self.scale_pos_weight = None
        
        # ConfiguraciÃ³n de cross-validation
        self.cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
        self.random_state = 42
        
    def calculate_scale_pos_weight(self, y_train: np.ndarray) -> float:
        """
        Calcular scale_pos_weight para datos desbalanceados
        """
        scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()
        logger.info(f"ðŸ“Š Scale pos weight calculado: {scale_pos_weight:.4f}")
        return scale_pos_weight
    
    def objective(self, trial, X_train: pd.DataFrame, y_train: pd.DataFrame) -> float:
        """
        FunciÃ³n objetivo para Optuna - reproduce exactamente el notebook
        """
        # Definir parÃ¡metros a optimizar con rangos amplios
        param = {
            'max_depth': trial.suggest_int('max_depth', 3, 10),
            'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.1, log=True),
            'n_estimators': trial.suggest_int('n_estimators', 300, 1500),  # mÃ¡s largo
            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),
            'gamma': trial.suggest_float('gamma', 0, 5),
            'reg_alpha': trial.suggest_float('reg_alpha', 1e-4, 10.0, log=True),
            'reg_lambda': trial.suggest_float('reg_lambda', 1e-4, 10.0, log=True),
            'subsample': trial.suggest_float('subsample', 0.5, 1),
            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1),
            'scale_pos_weight': self.scale_pos_weight,
            'use_label_encoder': False,
            'eval_metric': 'logloss',
            'random_state': 42,
            'n_jobs': -1
        }
        
        # Crear modelo con optimizaciones del notebook
        model = XGBClassifier(
            tree_method='hist',
            enable_categorical=True,
            **param
        )
        
        # Cross-validation estratificado
        val_f1_scores = []
        
        for train_idx, val_idx in self.cv.split(X_train, y_train):
            X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]
            y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]
            
            # Entrenar con early stopping
            try:
                model.fit(
                    X_tr, y_tr,
                    eval_set=[(X_val, y_val)],
                    early_stopping_rounds=100,
                    verbose=False
                )
            except TypeError:
                # VersiÃ³n nueva de XGBoost
                model.set_params(early_stopping_rounds=100)
                model.fit(
                    X_tr, y_tr,
                    eval_set=[(X_val, y_val)],
                    verbose=False
                )
            
            # Predicciones y F1-score
            y_val_pred = model.predict(X_val)
            val_f1_scores.append(f1_score(y_val, y_val_pred))
        
        # Retornar F1-score promedio (SIN penalizaciÃ³n por overfitting)
        return np.mean(val_f1_scores)
    
    def optimize(self, X_train: pd.DataFrame, y_train: pd.DataFrame) -> Dict[str, Any]:
        """
        Ejecutar optimizaciÃ³n con Optuna exactamente como en el notebook
        """
        logger.info("ðŸŽ¯ Iniciando 3er Tuning con Optuna - MetodologÃ­a Ganadora")
        logger.info(f"ðŸ”„ Optimizando con 100 trials usando TPESampler")
        
        # Calcular scale_pos_weight
        y_train_values = y_train.values if hasattr(y_train, 'values') else y_train
        self.scale_pos_weight = self.calculate_scale_pos_weight(y_train_values)
        
        # Configurar sampler exacto del notebook
        sampler = TPESampler(seed=42, multivariate=True, n_startup_trials=20)
        
        # Crear estudio
        self.study = optuna.create_study(direction='maximize', sampler=sampler)
        
        start_time = datetime.now()
        logger.info("ðŸš€ Iniciando optimizaciÃ³n bayesiana...")
        
        # Optimizar (reproduce exacto del notebook)
        self.study.optimize(
            lambda trial: self.objective(trial, X_train, y_train),
            n_trials=100,
            callbacks=[self._log_callback]
        )
        
        end_time = datetime.now()
        duration = end_time - start_time
        
        # Extraer mejores resultados
        self.best_score = self.study.best_value
        self.best_params = self.study.best_params.copy()
        
        # Agregar parÃ¡metros fijos
        self.best_params.update({
            'scale_pos_weight': self.scale_pos_weight,
            'use_label_encoder': False,
            'eval_metric': 'logloss',
            'random_state': 42,
            'n_jobs': -1,
            'tree_method': 'hist',
            'enable_categorical': True
        })
        
        logger.info(f"âœ… OptimizaciÃ³n completada en {duration}")
        logger.info(f"ðŸ† Mejor F1-Score: {self.best_score:.4f}")
        logger.info(f"ðŸŽ¯ Mejores parÃ¡metros: {self.best_params}")
        
        # Crear resumen de resultados
        results = {
            'best_params': self.best_params,
            'best_score': float(self.best_score),
            'n_trials': len(self.study.trials),
            'tuning_type': 'optuna_bayesian',
            'methodology': 'winner_notebook',
            'duration_seconds': duration.total_seconds(),
            'scale_pos_weight': float(self.scale_pos_weight),
            'timestamp': datetime.now().isoformat()
        }
        
        return results
    
    def _log_callback(self, study, trial):
        """Callback para logging del progreso"""
        if trial.number % 10 == 0:
            logger.info(f"Trial {trial.number}: F1-Score = {trial.value:.4f}")
    
    def get_best_model(self, X_train: pd.DataFrame, y_train: pd.DataFrame) -> XGBClassifier:
        """
        Entrenar modelo final con mejores parÃ¡metros
        """
        if self.best_params is None:
            raise ValueError("Debe ejecutar optimize() primero")
        
        logger.info("ðŸ¤– Entrenando modelo final con mejores parÃ¡metros...")
        
        # Crear modelo con mejores parÃ¡metros
        best_model = XGBClassifier(**self.best_params)
        
        # Entrenar en todo el conjunto
        best_model.fit(X_train, y_train)
        
        logger.info("âœ… Modelo final entrenado")
        return best_model
    
    def save_results(self, artifacts_dir: Path) -> None:
        """
        Guardar resultados completos del tuning Optuna
        """
        if self.best_params is None:
            raise ValueError("Debe ejecutar optimize() primero")
        
        artifacts_dir.mkdir(parents=True, exist_ok=True)
        
        # 1. Guardar mejores parÃ¡metros
        best_params_file = artifacts_dir / "best_params_optuna.json"
        with open(best_params_file, 'w') as f:
            json.dump(self.best_params, f, indent=2)
        logger.info(f"ðŸ’¾ Mejores parÃ¡metros guardados en {best_params_file}")
        
        # 2. Guardar estudio completo de Optuna
        study_file = artifacts_dir / "optuna_study.pkl"
        joblib.dump(self.study, study_file)
        logger.info(f"ðŸ“Š Estudio Optuna guardado en {study_file}")
        
        # 3. Guardar resumen de resultados
        results_summary = {
            'best_params': self.best_params,
            'best_f1_score': float(self.best_score),
            'n_trials': len(self.study.trials),
            'scale_pos_weight': float(self.scale_pos_weight),
            'sampler': 'TPESampler',
            'methodology': 'notebook_winner',
            'cv_folds': self.cv.n_splits,
            'timestamp': datetime.now().isoformat()
        }
        
        results_file = artifacts_dir / "optuna_results.json"
        with open(results_file, 'w') as f:
            json.dump(results_summary, f, indent=2)
        logger.info(f"ðŸ“ˆ Resumen completo guardado en {results_file}")
        
        # 4. Guardar histÃ³rico de trials
        trials_df = self.study.trials_dataframe()
        trials_file = artifacts_dir / "optuna_trials.csv"
        trials_df.to_csv(trials_file, index=False)
        logger.info(f"ðŸ“‹ HistÃ³rico de trials guardado en {trials_file}")

def find_optimal_threshold(model, X_val: pd.DataFrame, y_val: pd.DataFrame) -> Tuple[float, Dict[str, float]]:
    """
    Encontrar threshold Ã³ptimo usando precision-recall curve
    """
    logger.info("ðŸŽ¯ Buscando threshold Ã³ptimo...")
    
    # Obtener probabilidades
    y_proba = model.predict_proba(X_val)[:, 1]
    
    # Precision-Recall curve
    precision, recall, thresholds = precision_recall_curve(y_val, y_proba)
    
    # F1-score para cada threshold
    f1_scores = 2 * (precision * recall) / (precision + recall)
    f1_scores = np.nan_to_num(f1_scores)
    
    # Threshold Ã³ptimo
    optimal_idx = np.argmax(f1_scores)
    optimal_threshold = thresholds[optimal_idx] if optimal_idx < len(thresholds) else 0.5
    
    metrics = {
        'optimal_threshold': float(optimal_threshold),
        'optimal_f1': float(f1_scores[optimal_idx]),
        'optimal_precision': float(precision[optimal_idx]),
        'optimal_recall': float(recall[optimal_idx]),
        'roc_auc': float(roc_auc_score(y_val, y_proba))
    }
    
    logger.info(f"âœ… Threshold Ã³ptimo: {optimal_threshold:.4f}")
    logger.info(f"ðŸ“Š F1-score Ã³ptimo: {metrics['optimal_f1']:.4f}")
    logger.info(f"ðŸŽ¯ ROC-AUC: {metrics['roc_auc']:.4f}")
    
    return optimal_threshold, metrics

def run_third_tuning(X_train: pd.DataFrame, y_train: pd.DataFrame, 
                    X_val: pd.DataFrame, y_val: pd.DataFrame,
                    artifacts_dir: Path) -> Dict[str, Any]:
    """
    Ejecutar pipeline completo del 3er tuning con Optuna
    """
    logger.info("ðŸš€ Iniciando pipeline completo del 3er tuning con Optuna...")
    
    # 1. OptimizaciÃ³n de hiperparÃ¡metros con Optuna
    optimizer = OptunaXGBoostOptimizer()
    tuning_results = optimizer.optimize(X_train, y_train)
    
    # 2. Entrenar modelo final con mejores parÃ¡metros
    best_model = optimizer.get_best_model(X_train, y_train)
    
    # 3. Encontrar threshold Ã³ptimo
    optimal_threshold, threshold_metrics = find_optimal_threshold(
        best_model, X_val, y_val
    )
    
    # 4. Combinar resultados
    complete_results = {
        **tuning_results,
        'optimal_threshold': optimal_threshold,
        'threshold_metrics': threshold_metrics,
        'model': best_model
    }
    
    # 5. Guardar todo
    optimizer.save_results(artifacts_dir)
    
    # 6. Guardar modelo final
    model_file = artifacts_dir / "best_model_optuna.pkl"
    joblib.dump(best_model, model_file)
    logger.info(f"ðŸ¤– Modelo final guardado en {model_file}")
    
    # 7. Guardar threshold Ã³ptimo
    threshold_file = artifacts_dir / "optimal_threshold_optuna.json"
    with open(threshold_file, 'w') as f:
        json.dump({
            'threshold': optimal_threshold,
            'metrics': threshold_metrics,
            'timestamp': datetime.now().isoformat()
        }, f, indent=2)
    logger.info(f"ðŸŽ¯ Threshold Ã³ptimo guardado en {threshold_file}")
    
    logger.info("âœ… Pipeline completo del 3er tuning con Optuna completado")
    
    return complete_results

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    
    print("ðŸŽ¯ Script del 3er Tuning con Optuna - MetodologÃ­a Ganadora")
    print("Para ejecutar, usar run_pipeline.py que prepara los datos")
    print("Este script reproduce exactamente la optimizaciÃ³n del notebook")