# ğŸ› Pipeline Debug Guide

Esta guÃ­a te ayuda a debuggear y ejecutar el pipeline MLOps paso a paso.

## âœ… Quick Start (Ejecutar Todo)

```bash
# OpciÃ³n 1: Script de inicio rÃ¡pido
python quick_start.py

# OpciÃ³n 2: Pipeline manual
python pipeline/run_pipeline.py --data-path data/marketing_campaign.csv
```

## ğŸ” Debugging Paso a Paso

### 1. ValidaciÃ³n de Componentes

```bash
# Probar todos los componentes individualmente
python validate_pipeline.py
```

Este script valida:
- âœ… Carga de datos (formato semicolon separator)
- âœ… Feature engineering pipeline
- âœ… Third tuning module
- âœ… Temperature calibration (FIXED VERSION)
- âœ… Pipeline orchestrator

### 2. Tests BÃ¡sicos

```bash
# Tests de dependencias y datos bÃ¡sicos
python debug_test.py
```

### 3. Pipeline Manual por Pasos

Si necesitas ejecutar componentes individuales:

```python
# 1. Preparar datos
from pipeline.feature_engineering import prepare_data_for_training
data = prepare_data_for_training("data/marketing_campaign.csv")

# 2. Third Tuning
from pipeline.third_tuning import run_third_tuning
results = run_third_tuning(X_train, y_train, X_val, y_val, artifacts_dir)

# 3. Entrenamiento final
from pipeline.train_final import train_final_model_pipeline
model_results = train_final_model_pipeline(X_train, y_train, X_test, y_test, feature_names, artifacts_dir)

# 4. CalibraciÃ³n
from pipeline.temperature_calibration import calibrate_model_probabilities
calibrator = calibrate_model_probabilities(model, X_val, y_val, artifacts_dir)

# 5. SHAP Analysis
from pipeline.shap_analysis_pipeline import run_complete_shap_analysis
shap_results = run_complete_shap_analysis(model, X_test, feature_names, artifacts_dir)
```

## ğŸ› ï¸ Problemas Conocidos y Soluciones

### Error: "no se encontrÃ³ Python"
```bash
# Verificar Python path
python --version
# O usar python3
python3 quick_start.py
```

### Error: ModuleNotFoundError
```bash
# Instalar dependencias
pip install -r requirements.txt

# O individual:
pip install pandas numpy scikit-learn xgboost shap matplotlib seaborn joblib fastapi uvicorn
```

### Error: Dataset not found
```bash
# Verificar que el dataset estÃ© en la ubicaciÃ³n correcta:
data/marketing_campaign.csv
```

### Error: Separator issues
El dataset original usa separador semicolon (`;`), esto ya estÃ¡ configurado en el pipeline.

### Error: Temperature calibration
**âœ… FIXED**: El archivo `temperature_calibration.py` ha sido reparado y ahora funciona correctamente.

## ğŸ“Š Estructura del Pipeline

```
1. Feature Engineering â†’ 
2. Third Tuning (metodologÃ­a ganadora) â†’ 
3. Training Final â†’ 
4. Temperature Calibration â†’ 
5. SHAP Analysis
```

## ğŸ“ Artifacts Generados

DespuÃ©s de ejecutar el pipeline, encontrarÃ¡s:

```
artifacts/
â”œâ”€â”€ feature_pipeline.pkl          # Feature transformer
â”œâ”€â”€ final_model.pkl              # Modelo XGBoost entrenado
â”œâ”€â”€ temperature_calibrator.pkl   # Calibrador de temperatura
â”œâ”€â”€ calibration_metrics.json     # MÃ©tricas de calibraciÃ³n
â”œâ”€â”€ pipeline_summary.json        # Resumen completo
â”œâ”€â”€ plots/                       # GrÃ¡ficos de calibraciÃ³n
â”‚   â”œâ”€â”€ reliability_diagram.png
â”‚   â””â”€â”€ probability_distributions.png
â””â”€â”€ shap_values/                 # AnÃ¡lisis SHAP
    â”œâ”€â”€ shap_explainer.pkl
    â”œâ”€â”€ shap_values.pkl
    â””â”€â”€ plots/
```

## ğŸ¯ MÃ©tricas Esperadas

Un pipeline exitoso debe generar mÃ©tricas similares a:
- **ROC-AUC**: ~0.85-0.90
- **F1 Score**: ~0.60-0.70
- **Temperatura**: ~0.8-1.2

## ğŸ†˜ Si Todo Falla

1. **Ejecuta validaciÃ³n**: `python validate_pipeline.py`
2. **Revisa logs**: Busca errores especÃ­ficos en la salida
3. **Verifica datos**: AsegÃºrate que `data/marketing_campaign.csv` existe
4. **Prueba componentes**: Usa `debug_test.py` para tests bÃ¡sicos

## ğŸš€ Deploy a ProducciÃ³n

Una vez que el pipeline funcione:

```bash
# Servir modelo con FastAPI
python src/app.py

# Acceder a la API
curl -X POST "http://localhost:8000/predict" \
     -H "Content-Type: application/json" \
     -d '{"features": [values...]}'
```

## ğŸ“ Logs

Los logs del pipeline se guardan en `pipeline.log` para debugging detallado.